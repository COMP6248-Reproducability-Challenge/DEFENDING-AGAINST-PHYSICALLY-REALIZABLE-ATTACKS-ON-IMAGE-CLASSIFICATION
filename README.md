# DEFENDING AGAINST PHYSICALLY REALIZABLE ATTACKS ON IMAGE CLASSIFICATION
This repository is reproduce code about the article *DEFENDING AGAINST PHYSICAL REALIZABLE ATTACKS ON IMAGE CLASSIFICATION*.

**Original Paper**: Wu, T., Tong, L., & Vorobeychik, Y. (2019). Defending Against Physically Realizable Attacks on Image Classification. arXiv preprint arXiv:1909.09552, Available: https://arxiv.org/pdf/1909.09552.pdf

**Original Code**: https://github.com/tongwu2020/phattacks
```
The code for sign can found in './Sign'. 
ROA.py is used to generate the attack images. 
train.py is used to train original model and DOA Model. 
The code of ROA with two algorithms can be found in model.py
```

```
The code for VGGface can found in './VGGface'. 
```

## Dataset: 
* VGGface and LISA can be found: https://github.com/tongwu2020/phattacks/releases/tag/Data%26Model

## Pretrained_model:
* Weight of LISA DOA Model can be found:  './Sign/model_DOA.pkl'
* Weight of LISA Original Model can be found:  './Sign/model.pkl'
* Weight of VGG Model can be found: https://drive.google.com/file/d/1VXNEeivr_U9o2pf-YmWz4wgy2KoZvYlK/view?usp=sharing

## Authors
* **CHi Xu** [cx1g19@soton.ac.uk]()
* **Yin Bao** [yb1a19@soton.ac.uk]()
* **Zhaori Guo** [zg2n19@soton.ac.uk]()
